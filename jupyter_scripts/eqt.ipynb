{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e3c3d6",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811ad4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "062863df",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = 'C:/data/datasets/eqt/eqt_sakhalin_bandpass/eqt_seisan_1.h5'\n",
    "path_2 = 'C:/data/datasets/eqt/eqt_sakhalin_bandpass/eqt_seisan_3.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318124a",
   "metadata": {},
   "source": [
    "## Transform and merge data\n",
    "\n",
    "Model input data excpected in shape (None, 6000, 3) while we save data in shape (None, 3, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "394cea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_X(X):\n",
    "    \n",
    "    r_shape = (X.shape[0], X.shape[2], X.shape[1])\n",
    "    r_X = np.zeros(r_shape)\n",
    "    \n",
    "    for i in range(r_shape[0]):\n",
    "        for j in range(r_shape[2]):\n",
    "            r_X[i, :, j] = X[i, j, :]\n",
    "            \n",
    "    return r_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29654eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_N_E_Z(X):\n",
    "    \"\"\"\n",
    "    From Z, N, E to N, E, Z\n",
    "    \"\"\"\n",
    "    r_X = np.zeros(X.shape)\n",
    "    for i in range(X.shape[0]):\n",
    "        r_X[i, :, 0] = X[i, :, 1]\n",
    "        r_X[i, :, 1] = X[i, :, 2]\n",
    "        r_X[i, :, 2] = X[i, :, 0]\n",
    "        \n",
    "    return r_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9123766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_wave(x1, x2):\n",
    "    \n",
    "    shape = list(x1.shape)\n",
    "    shape[0] = x1.shape[0] + x2.shape[0]\n",
    "    shape = tuple(shape)\n",
    "    \n",
    "    r_x = np.zeros(shape)\n",
    "    \n",
    "    r_x[:x1.shape[0]] = x1\n",
    "    r_x[x1.shape[0]:] = x2\n",
    "    \n",
    "    return r_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2244fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_str(x1, x2):\n",
    "    \n",
    "    return list(x1) + list(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "94989c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(*paths, convert = True, to_n_e_z = True):\n",
    "    \n",
    "    Xs = []\n",
    "    Ps = []\n",
    "    Ss = []\n",
    "    \n",
    "    for path in paths:\n",
    "        with h5.File(path_1, 'r') as file:\n",
    "            \n",
    "            X = np.array(file['X'])\n",
    "            X = convert_X(X)\n",
    "            Xs.append(X)\n",
    "            \n",
    "            Ps.append(np.array(file['P']))\n",
    "            Ss.append(np.array(file['S']))\n",
    "\n",
    "    X = Xs[0]\n",
    "    P = Ps[0]\n",
    "    S = Ss[0]\n",
    "    for i in range(1, len(Xs)):\n",
    "\n",
    "        X = merge_wave(X, Xs[i])\n",
    "        P = merge_str(P, Ps[i])\n",
    "        S = merge_str(S, Ss[i])\n",
    "\n",
    "    X = to_N_E_Z(X)\n",
    "    \n",
    "    return X, P, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddbc5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, P, S = load_data(path_1, path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20fecad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2948, 6000, 3), 2948, 2948)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, len(P), len(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4969302",
   "metadata": {},
   "source": [
    "## Load EQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f911abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'C:/dev/EQTransformer/ModelsAndSampleData/EqT_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7d7028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31301d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying sys.path to be able to load project packages\n",
    "import sys\n",
    "sys.path.append('C:/dev/EQTransformer/EQTransformer/core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec3ff453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EqT_utils import f1, SeqSelfAttention, FeedForward, LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecb2eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path, \n",
    "                   custom_objects={'SeqSelfAttention': SeqSelfAttention, \n",
    "                                   'FeedForward': FeedForward,\n",
    "                                   'LayerNormalization': LayerNormalization, \n",
    "                                   'f1': f1                                                                            \n",
    "                                    })   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d7ff1b",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a926ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(X)\n",
    "\n",
    "np_results = np.array(results)\n",
    "np_results = np_results.reshape(np_results.shape[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd0e0e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2948, 6000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result label, input index, sample\n",
    "# Where 0 - detection label, 1 - p label, 2 - s label\n",
    "np_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb72957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eqt_wave_prediction(X, P, S, i_input, predictions, i_prediction = -1):\n",
    "    \n",
    "    if i_prediction == -1:\n",
    "        i_prediction = i_input\n",
    "    \n",
    "    p_positions = [int(x) for x in P[i_input].split(';') if len(x)]\n",
    "    s_positions = [int(x) for x in S[i_input].split(';') if len(x)]\n",
    "\n",
    "    data = X[i_input]\n",
    "    \n",
    "    fig = plt.figure(figsize = (7, 6), dpi = 160)\n",
    "    axes = fig.subplots(6, 1, sharex = True)\n",
    "    \n",
    "    pred = predictions[:, i_prediction, :]\n",
    "    \n",
    "    # Plot waveforms\n",
    "    for i in range(data.shape[1]):\n",
    "        axes[i].plot(data[:, i], linewidth = 0.5, color = '#000')\n",
    "\n",
    "    # Plot predictions\n",
    "    for i in range(pred.shape[0]):\n",
    "        axes[3 + i].plot(pred[i, :], 'g', linewidth = 0.5)\n",
    "        \n",
    "    # Mark seismic wave arrivals\n",
    "    for x in p_positions:\n",
    "        for i in range(data.shape[1]):\n",
    "            axes[i].plot(x, data[x, i], 'g^', markersize = 7)\n",
    "\n",
    "    for x in s_positions:\n",
    "        for i in range(data.shape[1]):\n",
    "            axes[i].plot(x, data[x, i], 'b^', markersize = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70e33da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3d42491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_validate(X, P, S, predictions, i,\n",
    "                       threshold = 0.2, min_distance = 200):\n",
    "    \n",
    "    p_positions = [int(x) for x in P[i].split(';') if len(x)]\n",
    "    s_positions = [int(x) for x in S[i].split(';') if len(x)]\n",
    "\n",
    "    data = X[i]\n",
    "    pred = predictions[:, i, :]\n",
    "    \n",
    "    result = {\n",
    "        'p':\n",
    "        {\n",
    "            'TP': 0,\n",
    "            'TN': 0,\n",
    "            'FP': 0,\n",
    "            'FN': 0,\n",
    "            'total': 0,\n",
    "        },\n",
    "        's':\n",
    "        {\n",
    "            'TP': 0,\n",
    "            'TN': 0,\n",
    "            'FP': 0,\n",
    "            'FN': 0,\n",
    "            'total': 0,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    # Get P predictions\n",
    "    p_peaks_init = find_peaks(pred[1, :], distance = min_distance, height=[threshold, 100.])[0]\n",
    "    \n",
    "    p_peaks = [x for x in p_peaks_init if x > min_distance and x < pred.shape[1] - min_distance]\n",
    "    \n",
    "    # Check True Negatives\n",
    "    if not len(p_peaks) and not len(p_positions):\n",
    "        result['p']['TN'] += 1\n",
    "    \n",
    "    # Check True Positives and False Positives\n",
    "    for peak_position in p_peaks:\n",
    "        \n",
    "        found = False\n",
    "        for real_position in p_positions:\n",
    "            if abs(real_position - peak_position) < min_distance:\n",
    "                result['p']['TP'] += 1\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            result['p']['FP'] += 1\n",
    "            \n",
    "    # Check False Negatives\n",
    "    for real_position in p_positions:\n",
    "        \n",
    "        found = False\n",
    "        for peak_position in p_peaks:\n",
    "            if abs(real_position - peak_position) < min_distance:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            result['p']['FN'] += 1\n",
    "    \n",
    "    # Get S predictions\n",
    "    s_peaks_init = find_peaks(pred[2, :], distance = min_distance, height=[threshold, 100.])[0]\n",
    "    \n",
    "    s_peaks = [x for x in s_peaks_init if x > min_distance and x < pred.shape[1] - min_distance]\n",
    "    \n",
    "    # Check True Negatives\n",
    "    if not len(s_peaks) and not len(s_positions):\n",
    "        result['s']['TN'] += 1\n",
    "    \n",
    "    # Check True Positives and False Positives\n",
    "    for peak_position in s_peaks:\n",
    "        \n",
    "        found = False\n",
    "        for real_position in s_positions:\n",
    "            if abs(real_position - peak_position) < min_distance:\n",
    "                result['s']['TP'] += 1\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            result['s']['FP'] += 1\n",
    "            \n",
    "    # Check False Negatives\n",
    "    for real_position in s_positions:\n",
    "        \n",
    "        found = False\n",
    "        for peak_position in s_peaks:\n",
    "            if abs(real_position - peak_position) < min_distance:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            result['s']['FN'] += 1\n",
    "\n",
    "    result['p']['total'] = result['p']['TP'] + result['p']['FP'] + result['p']['TN'] + result['p']['FN']\n",
    "    result['s']['total'] = result['s']['TP'] + result['s']['FP'] + result['s']['TN'] + result['s']['FN']\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88042c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': {'TP': 1, 'TN': 0, 'FP': 0, 'FN': 1, 'total': 2},\n",
       " 's': {'TP': 2, 'TN': 0, 'FP': 0, 'FN': 0, 'total': 2}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 110\n",
    "plot_eqt_wave_prediction(X, P, S, i, np_results); prediction_validate(X, P, S, np_results, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8d977",
   "metadata": {},
   "source": [
    "### Find peaks with more than 2 wave arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f09ead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "78\n",
      "110\n",
      "115\n",
      "147\n",
      "152\n",
      "183\n",
      "188\n",
      "210\n",
      "283\n",
      "298\n",
      "370\n",
      "385\n",
      "457\n",
      "472\n",
      "524\n",
      "566\n",
      "825\n",
      "1072\n",
      "1119\n",
      "1169\n",
      "1188\n",
      "1245\n",
      "1272\n",
      "1325\n",
      "1358\n",
      "1372\n",
      "1464\n",
      "1549\n",
      "1590\n",
      "2034\n",
      "2212\n",
      "2221\n",
      "2322\n",
      "2357\n",
      "2358\n",
      "2394\n",
      "2491\n",
      "2649\n",
      "2698\n"
     ]
    }
   ],
   "source": [
    "for i in range(X.shape[0]):\n",
    "    \n",
    "    p_positions = [int(x) for x in P[i].split(';') if len(x)]\n",
    "    s_positions = [int(x) for x in S[i].split(';') if len(x)]\n",
    "    \n",
    "    if len(p_positions) + len(s_positions) > 2:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aacf33",
   "metadata": {},
   "source": [
    "### Get total confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa5d4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metrics(x1, x2):\n",
    "    \n",
    "    r_x = {}\n",
    "    \n",
    "    for key, data in x1.items():\n",
    "        \n",
    "        if type(data) is dict:\n",
    "            r_x[key] = add_metrics(data, x2[key])\n",
    "            \n",
    "        else:\n",
    "            r_x[key] = data + x2[key]\n",
    "            \n",
    "    return r_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4758863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': {'TP': 396, 'TN': 599, 'FP': 17, 'FN': 1980, 'total': 2992},\n",
       " 's': {'TP': 356, 'TN': 153, 'FP': 130, 'FN': 2454, 'total': 3093}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = {\n",
    "    'p':\n",
    "    {\n",
    "        'TP': 0,\n",
    "        'TN': 0,\n",
    "        'FP': 0,\n",
    "        'FN': 0,\n",
    "        'total': 0,\n",
    "    },\n",
    "    's':\n",
    "    {\n",
    "        'TP': 0,\n",
    "        'TN': 0,\n",
    "        'FP': 0,\n",
    "        'FN': 0,\n",
    "        'total': 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    \n",
    "    metrics = prediction_validate(X, P, S, np_results, i)\n",
    "    result = add_metrics(result, metrics)\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36f7e8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['p']['TP'] + result['p']['FP'] + result['p']['TN'] + result['p']['FN'] == result['p']['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "954ded67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['s']['TP'] + result['s']['FP'] + result['s']['TN'] + result['s']['FN'] == result['s']['total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279e014",
   "metadata": {},
   "source": [
    "### P accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b30dd4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3325534759358289"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result['p']['TP'] + result['p']['TN']) / result['p']['total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f369077",
   "metadata": {},
   "source": [
    "### S accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dc32d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16456514710636921"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result['s']['TP'] + result['s']['TN']) / result['s']['total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f5c98d",
   "metadata": {},
   "source": [
    "## Normalized test (std normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2306f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, mode = 'std'):\n",
    "    \n",
    "    data -= np.mean(data, axis=0, keepdims=True)\n",
    "    \n",
    "    if mode == 'max':\n",
    "        max_data = np.max(data, axis=0, keepdims=True)\n",
    "        assert(max_data.shape[-1] == data.shape[-1])\n",
    "        max_data[max_data == 0] = 1\n",
    "        data /= max_data              \n",
    "\n",
    "    elif mode == 'std':               \n",
    "        std_data = np.std(data, axis=0, keepdims=True)\n",
    "        assert(std_data.shape[-1] == data.shape[-1])\n",
    "        std_data[std_data == 0] = 1\n",
    "        data /= std_data\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39486c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, P, S = load_data(path_1, path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57188a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[0]):\n",
    "    \n",
    "    X[i] = normalize(X[i], mode = 'std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb454dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(X)\n",
    "\n",
    "np_results = np.array(results)\n",
    "np_results = np_results.reshape(np_results.shape[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3f6a118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': {'TP': 1620, 'TN': 545, 'FP': 87, 'FN': 743, 'total': 2995},\n",
       " 's': {'TP': 1724, 'TN': 140, 'FP': 65, 'FN': 1074, 'total': 3003}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = {\n",
    "    'p':\n",
    "    {\n",
    "        'TP': 0,\n",
    "        'TN': 0,\n",
    "        'FP': 0,\n",
    "        'FN': 0,\n",
    "        'total': 0,\n",
    "    },\n",
    "    's':\n",
    "    {\n",
    "        'TP': 0,\n",
    "        'TN': 0,\n",
    "        'FP': 0,\n",
    "        'FN': 0,\n",
    "        'total': 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    \n",
    "    metrics = prediction_validate(X, P, S, np_results, i, threshold = 0.2)\n",
    "    result = add_metrics(result, metrics)\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f59cb6",
   "metadata": {},
   "source": [
    "### P accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6baac55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7228714524207012"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result['p']['TP'] + result['p']['TN']) / result['p']['total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd909a4",
   "metadata": {},
   "source": [
    "### S accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07d10d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6207126207126207"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result['s']['TP'] + result['s']['TN']) / result['s']['total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc1f81",
   "metadata": {},
   "source": [
    "## Normalized test (max normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15a2590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, P, S = load_data(path_1, path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b1978ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[0]):\n",
    "    \n",
    "    X[i] = normalize(X[i], mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22b55dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(X)\n",
    "\n",
    "np_results = np.array(results)\n",
    "np_results = np_results.reshape(np_results.shape[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7c0adc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': {'TP': 240, 'TN': 580, 'FP': 20, 'FN': 2143, 'total': 2983},\n",
       " 's': {'TP': 86, 'TN': 171, 'FP': 2, 'FN': 2733, 'total': 2992}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = {\n",
    "    'p':\n",
    "    {\n",
    "        'TP': 0,\n",
    "        'TN': 0,\n",
    "        'FP': 0,\n",
    "        'FN': 0,\n",
    "        'total': 0,\n",
    "    },\n",
    "    's':\n",
    "    {\n",
    "        'TP': 0,\n",
    "        'TN': 0,\n",
    "        'FP': 0,\n",
    "        'FN': 0,\n",
    "        'total': 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    \n",
    "    metrics = prediction_validate(X, P, S, np_results, i)\n",
    "    result = add_metrics(result, metrics)\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d8f5f",
   "metadata": {},
   "source": [
    "### P accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc94029f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27489104927924907"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result['p']['TP'] + result['p']['TN']) / result['p']['total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35967f6f",
   "metadata": {},
   "source": [
    "### S accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53d4ba20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08589572192513369"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result['s']['TP'] + result['s']['TN']) / result['s']['total']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
