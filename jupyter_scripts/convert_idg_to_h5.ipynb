{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9a392f",
   "metadata": {},
   "source": [
    "# convert_idg_to_h5\n",
    "\n",
    "This script converts IDG matlab dataset to .h5 dataset, similar to SP and GPD datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d7748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import obspy as obs\n",
    "from pathlib import Path\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "\n",
    "# Modifying sys.path to be able to load project packages\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# Load project packages\n",
    "from utils.h5_tools import write_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b11025",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 0\n",
    "path_in = 'C:/data/datasets/data_for_ML/events_data/'  # path to the dataset directory\n",
    "path_out = 'C:/data/datasets/data_for_ML_convertet/events.h5'\n",
    "data_keys = ['data_record', 0]\n",
    "time_keys = ['time_in', 0]\n",
    "\n",
    "preprocess = True\n",
    "\n",
    "in_df = 10000.\n",
    "out_df = 100.\n",
    "\n",
    "pick_length = 400  # samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d383fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(data, keys):\n",
    "    \"\"\"\n",
    "    Returns content of data, indexed by series of keys.\n",
    "    Usage Example:\n",
    "        data = get_content(dataset, [\"data_record\", \"Z\"])\n",
    "        Will return dataset[\"data_record\"][\"Z\"].\n",
    "    \"\"\"\n",
    "    for k in keys:\n",
    "        data = data[k]\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_channels(data, n_channels=3, normalize=True):\n",
    "    \"\"\"\n",
    "    Converts data to three-channel array (by duplicating data for each extra channel).\n",
    "    \"\"\"\n",
    "    n_samples = data.shape[0]\n",
    "    if normalize:\n",
    "        data[:] /= np.max(data)\n",
    "    X = np.zeros((n_samples, n_channels))\n",
    "    for i in range(n_channels):\n",
    "        X[:, i] = data[:]\n",
    "    return X\n",
    "\n",
    "\n",
    "def convert_file(path_in, data_keys, time_keys, preprocess=True):\n",
    "    \"\"\"\n",
    "    Converts seismic data from .mat dataset to miniSEED format.\n",
    "    \"\"\"\n",
    "    dataset = scipy.io.loadmat(path_in)\n",
    "    \n",
    "    # Check if there are multiple data or time entries\n",
    "    data = get_content(dataset, data_keys)\n",
    "    time = get_content(dataset, time_keys)\n",
    "\n",
    "    trace = obs.Trace(data)\n",
    "\n",
    "    trace.stats.sampling_rate = in_df\n",
    "\n",
    "    if preprocess:\n",
    "        trace.detrend(type=\"linear\")\n",
    "        trace.filter(type=\"highpass\", freq=2.)\n",
    "        \n",
    "    trace.resample(out_df)\n",
    "    \n",
    "    if preprocess:\n",
    "        trace.normalize()\n",
    "    \n",
    "    # Get data and label\n",
    "    data = trace.data\n",
    "    l_picks = []\n",
    "    for t in time:\n",
    "        \n",
    "        # Get pick span in sample positions\n",
    "        n_sample = int(t*out_df)\n",
    "        \n",
    "        start = int(n_sample - pick_length/2)\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        \n",
    "        end = int(start + pick_length)\n",
    "        if end > len(data):\n",
    "            end = len(data)\n",
    "            start = int(end - pick_length)\n",
    "            \n",
    "        # Get pick\n",
    "        pick = data[start:end]\n",
    "        pick = add_channels(pick)\n",
    "        \n",
    "        l_picks.append(pick)\n",
    "    \n",
    "    return l_picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a61bf90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir(path_in)  # load input file names\n",
    "# Path(path_out).mkdir(parents=True, exist_ok=True)  # create out directory if doesn't exists\n",
    "\n",
    "X = []\n",
    "for f_in in files:\n",
    "    f_in = os.path.join(path_in, f_in)\n",
    "    X.extend(convert_file(f_in, data_keys, time_keys, preprocess=preprocess))\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.full(X.shape[0], label, dtype = int)\n",
    "\n",
    "write_batch(path_out, 'X', X)\n",
    "write_batch(path_out, 'Y', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa75ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
